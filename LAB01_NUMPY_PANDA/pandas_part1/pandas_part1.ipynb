{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {\n",
    "    \"Name\":['kris', 'Ash', 'May', 'Dawn'], \n",
    "    \"Age\":[23,16,15,15],\n",
    "    \"City\":['Kalos', 'Kento', 'Henoi', 'Sinnoh']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age    City\n",
      "0  kris   23   Kalos\n",
      "1   Ash   16   Kento\n",
      "2   May   15   Henoi\n",
      "3  Dawn   15  Sinnoh\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dict1) #to construct a dataframe object\n",
    "print(df)\n",
    "#indexes are nothing but rows and headings are columns. indexes start from 0 by default and are appended infront of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('friends.csv') #to convert a data frame into comma seperated values file and save it\n",
    "df.to_csv('friends_index_false.csv', index = False) # to get rid of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age   City\n",
      "0  kris   23  Kalos\n",
      "1   Ash   16  Kento \n",
      "\n",
      "   Name  Age    City\n",
      "1   Ash   16   Kento\n",
      "2   May   15   Henoi\n",
      "3  Dawn   15  Sinnoh \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to view restricted rows in a data frame:\n",
    "print(df.head(2),'\\n') # first 2 rows/records\n",
    "print(df.tail(3),'\\n') # last 3 rows/records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Age\n",
      "count   4.00000\n",
      "mean   17.25000\n",
      "std     3.86221\n",
      "min    15.00000\n",
      "25%    15.00000\n",
      "50%    15.50000\n",
      "75%    17.75000\n",
      "max    23.00000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to get stats of numerical columns:\n",
    "print(df.describe(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train number  speed       city\n",
      "0         12221     35  ahmedabad\n",
      "1         20112    120     mumbai\n",
      "2         20010    360       pune\n",
      "3         43332     86      delhi\n"
     ]
    }
   ],
   "source": [
    "#to read a csv file which is already present in the folder:\n",
    "trains = pd.read_csv('trains.csv') \n",
    "print(trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     35\n",
      "1    120\n",
      "2    360\n",
      "3     86\n",
      "Name: speed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#to access a column of a dataframe (like dictionary only)\n",
    "print(trains['speed']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train number  speed       city\n",
      "0         12221    200  ahmedabad\n",
      "1         20112    120     mumbai\n",
      "2         20010    360       pune\n",
      "3         43332     86      delhi \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARSH\\AppData\\Local\\Temp\\ipykernel_7972\\959153449.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trains['speed'][0] = 200\n"
     ]
    }
   ],
   "source": [
    "#to access and change a value of the dataframe (like dictionary only)\n",
    "# although this works, we should not change values in dataframe like this. We will discuss the reason later on.\n",
    "trains['speed'][0] = 200\n",
    "print(trains,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to update the csv file in the folder:\n",
    "# trains.to_csv('trains.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        train number  speed       city\n",
      "first          12221    200  ahmedabad\n",
      "second         20112    120     mumbai\n",
      "third          20010    360       pune\n",
      "fourth         43332     86      delhi\n"
     ]
    }
   ],
   "source": [
    "#to change the indexing format:\n",
    "trains.index = ['first', 'second', 'third', 'fourth']\n",
    "print(trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mumbai\n"
     ]
    }
   ],
   "source": [
    "print(trains['city']['second']) #now you can use this indexing to get rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PANDAS SERIES IS A ONE DIMENTIONAL DATA STRUCTURE (sort of like column vector) WHICH CAN HOLD DATA OF ANY TYPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.691205\n",
      "1     0.426908\n",
      "2     0.488493\n",
      "3     0.671710\n",
      "4     0.256683\n",
      "5     0.135542\n",
      "6     0.212652\n",
      "7     0.771439\n",
      "8     0.130556\n",
      "9     0.546165\n",
      "10    0.155429\n",
      "11    0.269074\n",
      "12    0.692624\n",
      "13    0.594585\n",
      "14    0.112199\n",
      "15    0.216165\n",
      "16    0.424884\n",
      "17    0.490368\n",
      "18    0.536928\n",
      "19    0.817414\n",
      "dtype: float64 \n",
      "\n",
      "<class 'pandas.core.series.Series'> \n",
      "\n",
      "0.13554209227425407 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series(np.random.rand(20))\n",
    "print(ser,'\\n')\n",
    "print(type(ser),'\\n')\n",
    "print(ser[5],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PANDAS DATAFRAME IS A TWO DIMENTIONAL DATA STRUCTURE WHICH CAN HOLD MULTIPLE SERIES OR ARRAYS OR COLUMNS WITH DIFFERENT DATA TYPE ELEMENTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3\n",
      "0   0.997756  0.877487  0.401267\n",
      "1   0.221990  0.271778  0.921321\n",
      "2   0.870535  0.793812  0.093922\n",
      "3   0.651911  0.235065  0.292353\n",
      "4   0.757720  0.057464  0.402509\n",
      "5   0.312491  0.242250  0.850516\n",
      "6   0.904044  0.517113  0.590413\n",
      "7   0.948534  0.177507  0.876713\n",
      "8   0.711115  0.926866  0.239869\n",
      "9   0.450242  0.218081  0.098219\n",
      "10  0.426621  0.280005  0.431881\n",
      "11  0.907079  0.537089  0.307211\n",
      "12  0.621882  0.459242  0.679232\n",
      "13  0.624936  0.714154  0.789407\n",
      "14  0.567130  0.230058  0.562841\n",
      "15  0.584737  0.194991  0.548481\n",
      "16  0.172280  0.302154  0.715641\n",
      "17  0.916317  0.822276  0.781340\n",
      "18  0.489627  0.481115  0.741343\n",
      "19  0.242591  0.600438  0.332537\n",
      "<class 'pandas.core.frame.DataFrame'> \n",
      "\n",
      "1    float64\n",
      "2    float64\n",
      "3    float64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf = pd.DataFrame(np.random.rand(20,3), index = np.arange(20), columns=np.arange(1,4,1))\n",
    "print(newdf)\n",
    "print(type(newdf),'\\n')\n",
    "print(newdf.dtypes,'\\n')  #its 'dtypes' not 'dtype'!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3\n",
      "0      clay  0.877487  0.401267\n",
      "1   0.22199  0.271778  0.921321\n",
      "2  0.870535  0.793812  0.093922\n",
      "3  0.651911  0.235065  0.292353\n",
      "4   0.75772  0.057464  0.402509 \n",
      "\n",
      "1     object\n",
      "2    float64\n",
      "3    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "newdf[1][0] = 'clay'\n",
    "print(newdf.head(),'\\n') #if nothing in head parameter then by default it shows 5 rows\n",
    "print(newdf.dtypes) #note now the 0th index column has data type of object since it has both float and string as elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "            19],\n",
      "           dtype='int64') \n",
      "\n",
      "Int64Index([1, 2, 3], dtype='int64') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.index,'\\n')\n",
    "print(newdf.columns,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Age', 'City'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8976372242424 0.8774865928599472 0.4012671941939002]\n",
      " [0.22198972174677878 0.27177804367283964 0.9213209908288454]\n",
      " [0.8705348562565212 0.7938121876837585 0.09392163061442427]\n",
      " [0.6519107471816206 0.23506452455918359 0.29235325954383373]\n",
      " [0.7577201512320351 0.05746352285801615 0.402509145822771]\n",
      " [0.3124907532979201 0.2422500954606981 0.8505161874612011]\n",
      " [0.9040435129513175 0.5171128601753111 0.5904129720985458]\n",
      " [0.9485338247517606 0.17750732264496594 0.8767133985538875]\n",
      " [0.7111150927946513 0.9268661949019225 0.23986903706129603]\n",
      " [0.45024230448547586 0.21808129958601252 0.09821927479046633]\n",
      " [0.4266212749328886 0.2800050441029541 0.43188145385162224]\n",
      " [0.9070789413988041 0.537089467755647 0.3072109870604681]\n",
      " [0.6218820498942935 0.4592419386315869 0.6792322082339134]\n",
      " [0.6249355644259224 0.7141536600437628 0.7894067190363344]\n",
      " [0.5671301487370104 0.2300581024950955 0.5628414341365963]\n",
      " [0.5847372496142514 0.19499097846739888 0.5484812062733698]\n",
      " [0.17227952218954234 0.30215421771501627 0.7156410909411649]\n",
      " [0.9163173303013519 0.8222763544176886 0.7813395065612219]\n",
      " [0.4896273803140423 0.4811147356106139 0.7413434611606091]\n",
      " [0.24259126187150193 0.6004381887401569 0.33253718768724094]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf[1][0] = 0.8976372242424\n",
    "print(newdf.to_numpy(),'\\n') # to convert dataframe into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "1  0.897637   0.22199  0.870535  0.651911   0.75772  0.312491  0.904044   \n",
      "2  0.877487  0.271778  0.793812  0.235065  0.057464   0.24225  0.517113   \n",
      "3  0.401267  0.921321  0.093922  0.292353  0.402509  0.850516  0.590413   \n",
      "\n",
      "         7         8         9         10        11        12        13  \\\n",
      "1  0.948534  0.711115  0.450242  0.426621  0.907079  0.621882  0.624936   \n",
      "2  0.177507  0.926866  0.218081  0.280005  0.537089  0.459242  0.714154   \n",
      "3  0.876713  0.239869  0.098219  0.431881  0.307211  0.679232  0.789407   \n",
      "\n",
      "         14        15        16        17        18        19  \n",
      "1   0.56713  0.584737   0.17228  0.916317  0.489627  0.242591  \n",
      "2  0.230058  0.194991  0.302154  0.822276  0.481115  0.600438  \n",
      "3  0.562841  0.548481  0.715641   0.78134  0.741343  0.332537   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.T,'\\n') #to transpose the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3\n",
      "19  0.242591  0.600438  0.332537\n",
      "18  0.489627  0.481115  0.741343\n",
      "17  0.916317  0.822276  0.781340\n",
      "16   0.17228  0.302154  0.715641\n",
      "15  0.584737  0.194991  0.548481\n",
      "14   0.56713  0.230058  0.562841\n",
      "13  0.624936  0.714154  0.789407\n",
      "12  0.621882  0.459242  0.679232\n",
      "11  0.907079  0.537089  0.307211\n",
      "10  0.426621  0.280005  0.431881\n",
      "9   0.450242  0.218081  0.098219\n",
      "8   0.711115  0.926866  0.239869\n",
      "7   0.948534  0.177507  0.876713\n",
      "6   0.904044  0.517113  0.590413\n",
      "5   0.312491  0.242250  0.850516\n",
      "4    0.75772  0.057464  0.402509\n",
      "3   0.651911  0.235065  0.292353\n",
      "2   0.870535  0.793812  0.093922\n",
      "1    0.22199  0.271778  0.921321\n",
      "0   0.897637  0.877487  0.401267 \n",
      "\n",
      "           3         2         1\n",
      "0   0.401267  0.877487  0.897637\n",
      "1   0.921321  0.271778   0.22199\n",
      "2   0.093922  0.793812  0.870535\n",
      "3   0.292353  0.235065  0.651911\n",
      "4   0.402509  0.057464   0.75772\n",
      "5   0.850516  0.242250  0.312491\n",
      "6   0.590413  0.517113  0.904044\n",
      "7   0.876713  0.177507  0.948534\n",
      "8   0.239869  0.926866  0.711115\n",
      "9   0.098219  0.218081  0.450242\n",
      "10  0.431881  0.280005  0.426621\n",
      "11  0.307211  0.537089  0.907079\n",
      "12  0.679232  0.459242  0.621882\n",
      "13  0.789407  0.714154  0.624936\n",
      "14  0.562841  0.230058   0.56713\n",
      "15  0.548481  0.194991  0.584737\n",
      "16  0.715641  0.302154   0.17228\n",
      "17  0.781340  0.822276  0.916317\n",
      "18  0.741343  0.481115  0.489627\n",
      "19  0.332537  0.600438  0.242591 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.sort_index(axis = 0, ascending = False),'\\n')  #axis = 0 so it's for rows \n",
    "print(newdf.sort_index(axis = 1, ascending = False),'\\n')  #axis = 1 so it's for cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.897637\n",
      "1      0.22199\n",
      "2     0.870535\n",
      "3     0.651911\n",
      "4      0.75772\n",
      "5     0.312491\n",
      "6     0.904044\n",
      "7     0.948534\n",
      "8     0.711115\n",
      "9     0.450242\n",
      "10    0.426621\n",
      "11    0.907079\n",
      "12    0.621882\n",
      "13    0.624936\n",
      "14     0.56713\n",
      "15    0.584737\n",
      "16     0.17228\n",
      "17    0.916317\n",
      "18    0.489627\n",
      "19    0.242591\n",
      "Name: 1, dtype: object \n",
      "\n",
      "<class 'pandas.core.series.Series'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf[1],'\\n')  # NOTE THAT THIS WILL GIVE COLUMN NOT ROW!! WHICH HAPPENS GENEREALLY IN ANY LIST OR NP ARRAY.\n",
    "print(type(newdf[1]),'\\n')\n",
    "# SO COMBINATION OF SERIES MAKES A DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DIFFERENCE BETWEEN COPY AND VIEW: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3\n",
      "0   0.897637  0.877487  0.401267\n",
      "1        100  0.271778  0.921321\n",
      "2   0.870535  0.793812  0.093922\n",
      "3   0.651911  0.235065  0.292353\n",
      "4    0.75772  0.057464  0.402509\n",
      "5   0.312491  0.242250  0.850516\n",
      "6   0.904044  0.517113  0.590413\n",
      "7   0.948534  0.177507  0.876713\n",
      "8   0.711115  0.926866  0.239869\n",
      "9   0.450242  0.218081  0.098219\n",
      "10  0.426621  0.280005  0.431881\n",
      "11  0.907079  0.537089  0.307211\n",
      "12  0.621882  0.459242  0.679232\n",
      "13  0.624936  0.714154  0.789407\n",
      "14   0.56713  0.230058  0.562841\n",
      "15  0.584737  0.194991  0.548481\n",
      "16   0.17228  0.302154  0.715641\n",
      "17  0.916317  0.822276  0.781340\n",
      "18  0.489627  0.481115  0.741343\n",
      "19  0.242591  0.600438  0.332537 \n",
      "\n",
      "           1         2         3\n",
      "0   0.897637  0.877487  0.401267\n",
      "1        100  0.271778  0.921321\n",
      "2   0.870535  0.793812  0.093922\n",
      "3   0.651911  0.235065  0.292353\n",
      "4    0.75772  0.057464  0.402509\n",
      "5   0.312491  0.242250  0.850516\n",
      "6   0.904044  0.517113  0.590413\n",
      "7   0.948534  0.177507  0.876713\n",
      "8   0.711115  0.926866  0.239869\n",
      "9   0.450242  0.218081  0.098219\n",
      "10  0.426621  0.280005  0.431881\n",
      "11  0.907079  0.537089  0.307211\n",
      "12  0.621882  0.459242  0.679232\n",
      "13  0.624936  0.714154  0.789407\n",
      "14   0.56713  0.230058  0.562841\n",
      "15  0.584737  0.194991  0.548481\n",
      "16   0.17228  0.302154  0.715641\n",
      "17  0.916317  0.822276  0.781340\n",
      "18  0.489627  0.481115  0.741343\n",
      "19  0.242591  0.600438  0.332537 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf2 = newdf\n",
    "#newdf2 is a view of newdf, not a copy of it! hence both are pointing at the same values just like we had in python and numpy\n",
    "#so if i change anything in newdf2, it will change newdf also\n",
    "newdf2[1][1] = 100\n",
    "print(newdf2,'\\n')\n",
    "print(newdf,'\\n')\n",
    "# see both got changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1         2         3\n",
      "0   0.897637  0.877487  0.401267\n",
      "1        200  0.271778  0.921321\n",
      "2   0.870535  0.793812  0.093922\n",
      "3   0.651911  0.235065  0.292353\n",
      "4    0.75772  0.057464  0.402509\n",
      "5   0.312491  0.242250  0.850516\n",
      "6   0.904044  0.517113  0.590413\n",
      "7   0.948534  0.177507  0.876713\n",
      "8   0.711115  0.926866  0.239869\n",
      "9   0.450242  0.218081  0.098219\n",
      "10  0.426621  0.280005  0.431881\n",
      "11  0.907079  0.537089  0.307211\n",
      "12  0.621882  0.459242  0.679232\n",
      "13  0.624936  0.714154  0.789407\n",
      "14   0.56713  0.230058  0.562841\n",
      "15  0.584737  0.194991  0.548481\n",
      "16   0.17228  0.302154  0.715641\n",
      "17  0.916317  0.822276  0.781340\n",
      "18  0.489627  0.481115  0.741343\n",
      "19  0.242591  0.600438  0.332537 \n",
      "\n",
      "           1         2         3\n",
      "0   0.897637  0.877487  0.401267\n",
      "1        100  0.271778  0.921321\n",
      "2   0.870535  0.793812  0.093922\n",
      "3   0.651911  0.235065  0.292353\n",
      "4    0.75772  0.057464  0.402509\n",
      "5   0.312491  0.242250  0.850516\n",
      "6   0.904044  0.517113  0.590413\n",
      "7   0.948534  0.177507  0.876713\n",
      "8   0.711115  0.926866  0.239869\n",
      "9   0.450242  0.218081  0.098219\n",
      "10  0.426621  0.280005  0.431881\n",
      "11  0.907079  0.537089  0.307211\n",
      "12  0.621882  0.459242  0.679232\n",
      "13  0.624936  0.714154  0.789407\n",
      "14   0.56713  0.230058  0.562841\n",
      "15  0.584737  0.194991  0.548481\n",
      "16   0.17228  0.302154  0.715641\n",
      "17  0.916317  0.822276  0.781340\n",
      "18  0.489627  0.481115  0.741343\n",
      "19  0.242591  0.600438  0.332537 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARSH\\AppData\\Local\\Temp\\ipykernel_7972\\1751267931.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newdf3[1][1] = 200\n"
     ]
    }
   ],
   "source": [
    "#you can prevent this using copy() method \n",
    "newdf3 = newdf.copy()  # OR USE NEWDF3 = NEWDF[:] FOR COPYING\n",
    "newdf3[1][1] = 200\n",
    "print(newdf3,'\\n')\n",
    "print(newdf,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### THIS IS ALSO THE REASON WHY WE GOT THE WARNING OF SettingWithCopy when we tried to change the value of a dataframe element. when we are chaining (like doing newdf[1][0] = 100) then it is not a guarranty that we will get a view or a copy so we don't set a value like this, newdf[1][0] = 100 rather, we use loc and iloc methods. Always set values using loc or iloc!!!! loc and iloc are used to set as well as retrieve data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1         2         3\n",
      "0  300  0.877487  0.401267\n",
      "1  100  0.271778  0.921321 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.loc[0,1] = 300 # first parameter for row, second for column like usual np array \n",
    "print(newdf.head(2),'\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A         B         C\n",
      "0  300  0.877487  0.401267\n",
      "1  100  0.271778  0.921321 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.columns = list('ABC') # converted the string 'ABC' into a list and then that list is allocated as column names\n",
    "print(newdf.head(2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A         B         C\n",
      "0  500  0.877487  0.401267\n",
      "1  100  0.271778  0.921321 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.loc[0,'A'] = 500\n",
    "print(newdf.head(2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A         B         C     0\n",
      "0  500  0.877487  0.401267  99.0\n",
      "1  100  0.271778  0.921321   NaN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.loc[0,0] = 99 # this will create a new column with name 0 ! and rest of the values will be NAN\n",
    "print(newdf.head(2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A         B         C\n",
      "0  500  0.877487  0.401267\n",
      "1  100  0.271778  0.921321 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf = newdf.drop([0], axis = 1) # it will drop the 0 named column (cause axis = 1)\n",
    "print(newdf.head(2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          B         C\n",
      "1  0.271778  0.921321\n",
      "2  0.793812  0.093922\n",
      "4  0.057464  0.402509 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting elements from dataframe:\n",
    "print(newdf.loc[[1,2,4],['B','C']],'\\n') # this is only a view, hence inside the print. newdf is still intact. if you wanna change newdf then make newdf equal to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           B         C\n",
      "0   0.877487  0.401267\n",
      "1   0.271778  0.921321\n",
      "2   0.793812  0.093922\n",
      "3   0.235065  0.292353\n",
      "4   0.057464  0.402509\n",
      "5   0.242250  0.850516\n",
      "6   0.517113  0.590413\n",
      "7   0.177507  0.876713\n",
      "8   0.926866  0.239869\n",
      "9   0.218081  0.098219\n",
      "10  0.280005  0.431881\n",
      "11  0.537089  0.307211\n",
      "12  0.459242  0.679232\n",
      "13  0.714154  0.789407\n",
      "14  0.230058  0.562841\n",
      "15  0.194991  0.548481\n",
      "16  0.302154  0.715641\n",
      "17  0.822276  0.781340\n",
      "18  0.481115  0.741343\n",
      "19  0.600438  0.332537 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.loc[:, ['B','C']],'\\n') # to get all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "1       100  0.271778  0.921321\n",
      "2  0.870535  0.793812  0.093922\n",
      "4   0.75772  0.057464  0.402509 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.loc[[1,2,4], :],'\\n') # to get all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### some advanced queries with masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1      True\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5      True\n",
       "6     False\n",
       "7      True\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13     True\n",
       "14    False\n",
       "15    False\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making the mask:\n",
    "((newdf[\"A\"] < 0.3) | (newdf['C'] > 0.7)) #remember first argument is column in dataframe not row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A         B         C\n",
      "1        100  0.271778  0.921321\n",
      "5   0.312491  0.242250  0.850516\n",
      "7   0.948534  0.177507  0.876713\n",
      "13  0.624936  0.714154  0.789407\n",
      "16   0.17228  0.302154  0.715641\n",
      "17  0.916317  0.822276  0.781340\n",
      "18  0.489627  0.481115  0.741343\n",
      "19  0.242591  0.600438  0.332537 \n",
      "\n",
      "          A         B         C\n",
      "16  0.17228  0.302154  0.715641 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.loc[((newdf[\"A\"] < 0.3) | (newdf['C'] > 0.7))],'\\n') #remember first argument is column in dataframe not row.\n",
    "print(newdf.loc[((newdf[\"A\"] < 0.3) & (newdf['C'] > 0.7))],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DIFFERENCE BETWEEN LOC AND ILOC: IN LOC YOU HAVE TO USE THE NAMES GIVEN TO ROWS AND COLS IN ORDER TO ACCESS THEM. IN ILOC YOU HAVE TO USE THE 0 INDEXING TO ACCESS BOTH ROWS AND COLS IRRESPECTIVE OF THE NAMES OF THE ROWS AND COLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.877487\n",
      "1     0.271778\n",
      "2     0.793812\n",
      "3     0.235065\n",
      "4     0.057464\n",
      "5     0.242250\n",
      "6     0.517113\n",
      "7     0.177507\n",
      "8     0.926866\n",
      "9     0.218081\n",
      "10    0.280005\n",
      "11    0.537089\n",
      "12    0.459242\n",
      "13    0.714154\n",
      "14    0.230058\n",
      "15    0.194991\n",
      "16    0.302154\n",
      "17    0.822276\n",
      "18    0.481115\n",
      "19    0.600438\n",
      "Name: B, dtype: float64 \n",
      "\n",
      "0     0.877487\n",
      "1     0.271778\n",
      "2     0.793812\n",
      "3     0.235065\n",
      "4     0.057464\n",
      "5     0.242250\n",
      "6     0.517113\n",
      "7     0.177507\n",
      "8     0.926866\n",
      "9     0.218081\n",
      "10    0.280005\n",
      "11    0.537089\n",
      "12    0.459242\n",
      "13    0.714154\n",
      "14    0.230058\n",
      "15    0.194991\n",
      "16    0.302154\n",
      "17    0.822276\n",
      "18    0.481115\n",
      "19    0.600438\n",
      "Name: B, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.iloc[:, 1],'\\n') #this will give nothing by 'B' column\n",
    "print(newdf.loc[:, 'B'],'\\n') # see same output as above\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           B\n",
      "0   0.877487\n",
      "1   0.271778\n",
      "2   0.793812\n",
      "3   0.235065\n",
      "4   0.057464\n",
      "5   0.242250\n",
      "6   0.517113\n",
      "7   0.177507\n",
      "8   0.926866\n",
      "9   0.218081\n",
      "10  0.280005\n",
      "11  0.537089\n",
      "12  0.459242\n",
      "13  0.714154\n",
      "14  0.230058\n",
      "15  0.194991\n",
      "16  0.302154\n",
      "17  0.822276\n",
      "18  0.481115\n",
      "19  0.600438 \n",
      "\n",
      "           B\n",
      "0   0.877487\n",
      "1   0.271778\n",
      "2   0.793812\n",
      "3   0.235065\n",
      "4   0.057464\n",
      "5   0.242250\n",
      "6   0.517113\n",
      "7   0.177507\n",
      "8   0.926866\n",
      "9   0.218081\n",
      "10  0.280005\n",
      "11  0.537089\n",
      "12  0.459242\n",
      "13  0.714154\n",
      "14  0.230058\n",
      "15  0.194991\n",
      "16  0.302154\n",
      "17  0.822276\n",
      "18  0.481115\n",
      "19  0.600438 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf.drop(['A','C'], axis = 1),'\\n') #this won't change the dataframe, it's only for view. if you wanna change the make dfnew equal to this.\n",
    "newdf.drop(['A','C'], axis = 1, inplace = True) #this will overide the dataframe. since inplace is true.\n",
    "print(newdf,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          B\n",
      "0  0.877487\n",
      "2  0.793812\n",
      "3  0.235065\n",
      "5  0.242250\n",
      "6  0.517113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.drop([1,4], axis = 0, inplace = True) # dropping rows\n",
    "print(newdf.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          B\n",
      "0  0.877487\n",
      "1  0.793812\n",
      "2  0.235065\n",
      "3  0.242250\n",
      "4  0.517113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to reset the index after you have dropped some rows:\n",
    "newdf.reset_index(drop = True, inplace = True) # drop=true to get rid of that index column of previous indexes\n",
    "print(newdf.head(),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index         B\n",
      "0      0  0.877487\n",
      "1      1  0.793812\n",
      "2      2  0.235065\n",
      "3      3  0.242250\n",
      "4      4  0.517113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf = newdf.reset_index() #to have one more col as previous indexes\n",
    "print(newdf.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   previous index         B\n",
      "0               0  0.877487\n",
      "1               1  0.793812\n",
      "2               2  0.235065\n",
      "3               3  0.242250\n",
      "4               4  0.517113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.columns = ['previous index', 'B']\n",
    "print(newdf.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   previous index         B\n",
      "0               0  0.877487\n",
      "1               0  0.793812\n",
      "2               0  0.235065\n",
      "3               0  0.242250\n",
      "4               0  0.517113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.loc[:, 'previous index'] = 0\n",
    "print(newdf.head(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "Name: previous index, dtype: bool \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newdf['previous index'].isnull(),'\\n') # all false because they have some value (0 in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4      True\n",
      "5      True\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "Name: previous index, dtype: bool \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.loc[0:5, 'previous index'] = None\n",
    "print(newdf['previous index'].isnull(),'\\n') # true when some values are not present or null or None or NaN or blank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name        toy       born\n",
      "0    Alfred        NaN        NaT\n",
      "1    Batman  Batmobile 1940-04-25\n",
      "2  Catwoman   Bullwhip        NaT \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newestdf = pd.DataFrame({\n",
    "    \"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
    "    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"), pd.NaT]\n",
    "    }\n",
    ")\n",
    "print(newestdf,'\\n') # pd.NaT is missing date. np.nan is not a number or null/None value or missing value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "newestdf1 = newestdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name        toy       born\n",
      "1  Batman  Batmobile 1940-04-25 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newestdf.dropna(axis = 0, how = 'any', inplace = True) #removed all the missing element rows. axis = 1 for removing missing element cols\n",
    "# if how was 'all' then it would remove row only if all elements of that row had missing values\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "print(newestdf,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name        toy       born\n",
      "0  Catwoman        NaN        NaT\n",
      "1    Batman  Batmobile 1940-04-25\n",
      "2  Catwoman   Bullwhip        NaT \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newestdf1.loc[0, 'name'] = 'Catwoman'\n",
    "print(newestdf1,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name        toy       born\n",
      "1    Batman  Batmobile 1940-04-25\n",
      "2  Catwoman   Bullwhip        NaT \n",
      "\n"
     ]
    }
   ],
   "source": [
    "newestdf1.drop_duplicates(subset=['name'], keep = 'last', inplace = True)\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "print(newestdf1,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newestdf1.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2 entries, 1 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   name    2 non-null      object        \n",
      " 1   toy     2 non-null      object        \n",
      " 2   born    1 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 64.0+ bytes\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newestdf1.info(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batmobile    1\n",
      "Bullwhip     1\n",
      "Name: toy, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newestdf1['toy'].value_counts(dropna=False),'\\n') #if dropna = False then it will also count the missing values and how many of them are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940-04-25    1\n",
      "Name: born, dtype: int64 \n",
      "\n",
      "1940-04-25    1\n",
      "NaT           1\n",
      "Name: born, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newestdf1['born'].value_counts(dropna=True),'\\n')\n",
    "print(newestdf1['born'].value_counts(dropna=False),'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    toy   born\n",
      "1  False  False  False\n",
      "2  False  False   True \n",
      "\n",
      "   name   toy   born\n",
      "1  True  True   True\n",
      "2  True  True  False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newestdf1.isnull(),'\\n')\n",
    "print(newestdf1.notnull(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name        toy                 born\n",
      "1    Batman  Batmobile  1940-04-25 00:00:00\n",
      "2  Catwoman   Bullwhip              missing\n"
     ]
    }
   ],
   "source": [
    "print(newestdf1.fillna(\"missing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw = pd.DataFrame({\n",
    "    'height':[170,169,162],\n",
    "    'weight':[68,65,52]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   height  weight\n",
      "0     170      68\n",
      "1     169      65\n",
      "2     162      52 \n",
      "\n",
      "mean\n",
      " height    167.000000\n",
      "weight     61.666667\n",
      "dtype: float64 \n",
      "\n",
      "median\n",
      " height    169.0\n",
      "weight     65.0\n",
      "dtype: float64 \n",
      "\n",
      "mode\n",
      "    height  weight\n",
      "0     162      52\n",
      "1     169      65\n",
      "2     170      68 \n",
      "\n",
      "max\n",
      " height    170\n",
      "weight     68\n",
      "dtype: int64 \n",
      "\n",
      "min\n",
      " height    162\n",
      "weight     52\n",
      "dtype: int64 \n",
      "\n",
      "count\n",
      " height    3\n",
      "weight    3\n",
      "dtype: int64 \n",
      "\n",
      "variance\n",
      " height    19.000000\n",
      "weight    72.333333\n",
      "dtype: float64 \n",
      "\n",
      "standard deviation\n",
      " height    4.358899\n",
      "weight    8.504901\n",
      "dtype: float64 \n",
      "\n",
      "correlation\n",
      "           height    weight\n",
      "height  1.000000  0.998058\n",
      "weight  0.998058  1.000000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(hw,'\\n')\n",
    "print(\"mean\\n\",hw.mean(),'\\n')\n",
    "print(\"median\\n\",hw.median(),'\\n')\n",
    "print(\"mode\\n\",hw.mode(),'\\n')\n",
    "print(\"max\\n\",hw.max(),'\\n')\n",
    "print(\"min\\n\",hw.min(),'\\n')\n",
    "print(\"count\\n\",hw.count(),'\\n')\n",
    "print(\"variance\\n\",hw.var(),'\\n')\n",
    "print(\"standard deviation\\n\",hw.std(),'\\n')\n",
    "print(\"correlation\\n\",hw.corr(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp id           name     hobbie\n",
      "0      45         dwayne  wrestling\n",
      "1      56         connor        MMA\n",
      "2     109  lee chong wei  badminton\n"
     ]
    }
   ],
   "source": [
    "# reading from excel file\n",
    "data = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to excel file\n",
    "data.iloc[1,2] = 'trash talk'\n",
    "\n",
    "data.to_excel('data_new.xlsx', sheet_name='Sheet1', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download iris dataset from kaggle. It contains 6 columns and 150 rows of 3 different sepcies of flowers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make a dataframe of the csv file. After that, make three dataframes, containing 50 rows each for all the three different species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Build a new dataframe, \"train_df\" containing 40 rows from each of the three species dataframes. Hence containing 120 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. similarly build another dataframe, \"test_df\" containing the rest 10 rows from each of the three species dataframes. Hence containing 30 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Check for any NaN or missing values in the dataframes. If present, replace them with 0 if the column type is numeric, else replace with \"missing\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Display the column types in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. without using any inbuilt numpy or pandas functions, compute the mean, mode, median, variance, standard deviation, max, min of each numerical column in both train and test dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Without using any inbuilt numpy or pandas function, compute the correlation between each pair of columns (neglect ID and species column) in both train and test dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. In train dataset, take the two columns having the highest correlation and fit a line between them using the linear regression class of sklearn. For Example, suppose SepalLength and SepalWidth has highest correlation, then you have to predict SepalLength, given SepalWidth (this is nothing but 2D LinearRegression). After that, Plot the line alongwith the corresponding SepalLength and SepalWidth Values from the test_df dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Predict the value of SepalLength for every 30 values of SepalWidth in the test_df dataframe using the predicted line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Compute the Mean squared error between the predictions and real sepalLengh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: it might be possible that the two highest correlating columns are not sepal length and sepal width but let's say they are \"x\" and \"y\", in which case just do the exercise with those \"x\" and \"y\" columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. At this point you would have predicted \"x\" column using \"y\" column and computed the error in the test_df. You have to do the same whole process, but this time you have to predict \"x\" column using not only \"y\" column but also the remaining 2 columns (whichever it be). Again compute the error. No need to plot or draw anything as it will be 4 dimensional now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Conclude which of the two methods produced less Mean square error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a50c67c2899eff48b42ce193594db3f0465d411cbcbdad9a91476e0c1ace7634"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
